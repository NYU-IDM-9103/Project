# Milestone 1: Ideation and High-Level Description

### Option 1
**Destroying optimality**

I wanted to critique the obsession with perfection and optimization in technology, especially in ML algorithms, which is usually related to either some form of accuracy or efficiency. Destroying it would allow the artist to reveal the machine's "flaws" in a way, maybe humanize its outputs, or highlight the subjectivity of what we consider "ideal". A more philosophical question would then be: if ML models are not striving for perfection, are they still fulfilling their purpose? Partly inspired by glitchy typewriter example from the first code translation homework. 

Some ideas include:
- Corrupting training data by feeding incomplete, conflicting, or nonsensical data to disrupt the learning process
- Randomly modifying hyperparameters during tuning
- Extract the outputs from intermediate layers of neural networks

Example artists: [Rosa Menkman](https://www.loosenart.com/blogs/magazine/the-punctum-as-glitch-in-contemporary-art-the-art-of-rosa-menkman), [Mario Klingermann - Neural Glitch](https://underdestruction.com/2018/10/28/neural-glitch/)

### Option 2
**Breaking biases**

I wanted to explore the concept of how difficult it would be to break ingrained biases by using a parallel in ML world where ML models learn latent spaces, and even when you feed random noise into these spaces, the model generates outputs adhering to its trained biases. For example, a model trained on human faces will output faces—even from random noise—because the latent space is optimized for that. We can try to disrupt this process by feeding noise or unconventional inputs into the latent space, maybe even using deliberately misaligned inputs like noise with extreme deviations to try to force the model to generate outputs that struggle to "fit" its training biases. 

By forcing random or disruptive inputs, it showcases the model's limitations and reveals how strongly biases dictate outputs. It also begs the question "can ML systems truly imagine beyond what they've been trained on?"

Example artists: [Sofia Crespo - Critically Extant](https://sofiacrespo.com/critically-extant/), [Jake Elwes - Latent Space](https://www.jakeelwes.com/project-latentSpace.html)
